{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dependencies\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "                 age  detailed industry recode  detailed occupation recode  \\\ncount  199523.000000             199523.000000               199523.000000   \nmean       34.494199                 15.352320                   11.306556   \nstd        22.310895                 18.067129                   14.454204   \nmin         0.000000                  0.000000                    0.000000   \n25%        15.000000                  0.000000                    0.000000   \n50%        33.000000                  0.000000                    0.000000   \n75%        50.000000                 33.000000                   26.000000   \nmax        90.000000                 51.000000                   46.000000   \n\n       wage per hour  capital gains  capital losses  dividends from stocks  \\\ncount  199523.000000   199523.00000   199523.000000          199523.000000   \nmean       55.426908      434.71899       37.313788             197.529533   \nstd       274.896454     4697.53128      271.896428            1984.163658   \nmin         0.000000        0.00000        0.000000               0.000000   \n25%         0.000000        0.00000        0.000000               0.000000   \n50%         0.000000        0.00000        0.000000               0.000000   \n75%         0.000000        0.00000        0.000000               0.000000   \nmax      9999.000000    99999.00000     4608.000000           99999.000000   \n\n       instance weight  num persons worked for employer  \\\ncount    199523.000000                    199523.000000   \nmean       1740.380269                         1.956180   \nstd         993.768156                         2.365126   \nmin          37.870000                         0.000000   \n25%        1061.615000                         0.000000   \n50%        1618.310000                         1.000000   \n75%        2188.610000                         4.000000   \nmax       18656.300000                         6.000000   \n\n       own business or self employed  veterans benefits  weeks worked in year  \\\ncount                  199523.000000      199523.000000         199523.000000   \nmean                        0.175438           1.514833             23.174897   \nstd                         0.553694           0.851473             24.411488   \nmin                         0.000000           0.000000              0.000000   \n25%                         0.000000           2.000000              0.000000   \n50%                         0.000000           2.000000              8.000000   \n75%                         0.000000           2.000000             52.000000   \nmax                         2.000000           2.000000             52.000000   \n\n                year  \ncount  199523.000000  \nmean       94.499672  \nstd         0.500001  \nmin        94.000000  \n25%        94.000000  \n50%        94.000000  \n75%        95.000000  \nmax        95.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>detailed industry recode</th>\n      <th>detailed occupation recode</th>\n      <th>wage per hour</th>\n      <th>capital gains</th>\n      <th>capital losses</th>\n      <th>dividends from stocks</th>\n      <th>instance weight</th>\n      <th>num persons worked for employer</th>\n      <th>own business or self employed</th>\n      <th>veterans benefits</th>\n      <th>weeks worked in year</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.00000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n      <td>199523.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>34.494199</td>\n      <td>15.352320</td>\n      <td>11.306556</td>\n      <td>55.426908</td>\n      <td>434.71899</td>\n      <td>37.313788</td>\n      <td>197.529533</td>\n      <td>1740.380269</td>\n      <td>1.956180</td>\n      <td>0.175438</td>\n      <td>1.514833</td>\n      <td>23.174897</td>\n      <td>94.499672</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>22.310895</td>\n      <td>18.067129</td>\n      <td>14.454204</td>\n      <td>274.896454</td>\n      <td>4697.53128</td>\n      <td>271.896428</td>\n      <td>1984.163658</td>\n      <td>993.768156</td>\n      <td>2.365126</td>\n      <td>0.553694</td>\n      <td>0.851473</td>\n      <td>24.411488</td>\n      <td>0.500001</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>37.870000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>94.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>15.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1061.615000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>94.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>33.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1618.310000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>8.000000</td>\n      <td>94.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>50.000000</td>\n      <td>33.000000</td>\n      <td>26.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2188.610000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>52.000000</td>\n      <td>95.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>90.000000</td>\n      <td>51.000000</td>\n      <td>46.000000</td>\n      <td>9999.000000</td>\n      <td>99999.00000</td>\n      <td>4608.000000</td>\n      <td>99999.000000</td>\n      <td>18656.300000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>52.000000</td>\n      <td>95.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusIncome = pd.read_csv('../data/census-income.data', sep=',')\n",
    "censusIncome.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "censusIncome.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "       class of worker  detailed industry recode  detailed occupation recode  \\\n5              Private                        40                          10   \n8     Local government                        43                          26   \n22             Private                        35                          22   \n49             Private                        37                          36   \n147   State government                        43                          23   \n\n                                education enroll in edu inst last wk  \\\n5              Some college but no degree            Not in universe   \n8              Some college but no degree            Not in universe   \n22             Some college but no degree            Not in universe   \n49             Some college but no degree            Not in universe   \n147   Associates degree-occup /vocational      College or university   \n\n                         marital stat                 major industry code  \\\n5     Married-civilian spouse present                       Entertainment   \n8     Married-civilian spouse present                           Education   \n22    Married-civilian spouse present   Finance insurance and real estate   \n49    Married-civilian spouse present        Business and repair services   \n147        Married-A F spouse present                           Education   \n\n                      major occupation code                          race  \\\n5                    Professional specialty   Amer Indian Aleut or Eskimo   \n8            Adm support including clerical                         White   \n22           Adm support including clerical                         White   \n49    Machine operators assmblrs & inspctrs                         White   \n147          Adm support including clerical                         White   \n\n    hispanic origin  ... country of birth father country of birth mother  \\\n5         All other  ...             Philippines           United-States   \n8         All other  ...           United-States           United-States   \n22        All other  ...           United-States           United-States   \n49        All other  ...           United-States           United-States   \n147       All other  ...           United-States           United-States   \n\n    country of birth self                         citizenship  \\\n5           United-States   Native- Born in the United States   \n8           United-States   Native- Born in the United States   \n22          United-States   Native- Born in the United States   \n49          United-States   Native- Born in the United States   \n147         United-States   Native- Born in the United States   \n\n     own business or self employed  \\\n5                                2   \n8                                0   \n22                               2   \n49                               0   \n147                              2   \n\n     fill inc questionnaire for veteran's admin  veterans benefits  \\\n5                               Not in universe                  2   \n8                               Not in universe                  2   \n22                              Not in universe                  2   \n49                              Not in universe                  2   \n147                             Not in universe                  2   \n\n    weeks worked in year          age_label wage_label  \n5                     52              25-54     0-3000  \n8                     52              25-54     0-3000  \n22                    32              55-64     0-3000  \n49                    52  65 years and over     0-3000  \n147                   48              15-24     0-3000  \n\n[5 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class of worker</th>\n      <th>detailed industry recode</th>\n      <th>detailed occupation recode</th>\n      <th>education</th>\n      <th>enroll in edu inst last wk</th>\n      <th>marital stat</th>\n      <th>major industry code</th>\n      <th>major occupation code</th>\n      <th>race</th>\n      <th>hispanic origin</th>\n      <th>...</th>\n      <th>country of birth father</th>\n      <th>country of birth mother</th>\n      <th>country of birth self</th>\n      <th>citizenship</th>\n      <th>own business or self employed</th>\n      <th>fill inc questionnaire for veteran's admin</th>\n      <th>veterans benefits</th>\n      <th>weeks worked in year</th>\n      <th>age_label</th>\n      <th>wage_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Private</td>\n      <td>40</td>\n      <td>10</td>\n      <td>Some college but no degree</td>\n      <td>Not in universe</td>\n      <td>Married-civilian spouse present</td>\n      <td>Entertainment</td>\n      <td>Professional specialty</td>\n      <td>Amer Indian Aleut or Eskimo</td>\n      <td>All other</td>\n      <td>...</td>\n      <td>Philippines</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>Native- Born in the United States</td>\n      <td>2</td>\n      <td>Not in universe</td>\n      <td>2</td>\n      <td>52</td>\n      <td>25-54</td>\n      <td>0-3000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Local government</td>\n      <td>43</td>\n      <td>26</td>\n      <td>Some college but no degree</td>\n      <td>Not in universe</td>\n      <td>Married-civilian spouse present</td>\n      <td>Education</td>\n      <td>Adm support including clerical</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>Native- Born in the United States</td>\n      <td>0</td>\n      <td>Not in universe</td>\n      <td>2</td>\n      <td>52</td>\n      <td>25-54</td>\n      <td>0-3000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Private</td>\n      <td>35</td>\n      <td>22</td>\n      <td>Some college but no degree</td>\n      <td>Not in universe</td>\n      <td>Married-civilian spouse present</td>\n      <td>Finance insurance and real estate</td>\n      <td>Adm support including clerical</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>Native- Born in the United States</td>\n      <td>2</td>\n      <td>Not in universe</td>\n      <td>2</td>\n      <td>32</td>\n      <td>55-64</td>\n      <td>0-3000</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Private</td>\n      <td>37</td>\n      <td>36</td>\n      <td>Some college but no degree</td>\n      <td>Not in universe</td>\n      <td>Married-civilian spouse present</td>\n      <td>Business and repair services</td>\n      <td>Machine operators assmblrs &amp; inspctrs</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>Native- Born in the United States</td>\n      <td>0</td>\n      <td>Not in universe</td>\n      <td>2</td>\n      <td>52</td>\n      <td>65 years and over</td>\n      <td>0-3000</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>State government</td>\n      <td>43</td>\n      <td>23</td>\n      <td>Associates degree-occup /vocational</td>\n      <td>College or university</td>\n      <td>Married-A F spouse present</td>\n      <td>Education</td>\n      <td>Adm support including clerical</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>...</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>United-States</td>\n      <td>Native- Born in the United States</td>\n      <td>2</td>\n      <td>Not in universe</td>\n      <td>2</td>\n      <td>48</td>\n      <td>15-24</td>\n      <td>0-3000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories the age label otherwise, the encoding won't work very well\n",
    "censusIncome['age_label'] = censusIncome['age'].apply(lambda value: '0-14'\n",
    "if value <= 14 else '15-24'\n",
    "if value <= 24 else '25-54'\n",
    "if value <= 54 else '55-64'\n",
    "if value <= 64 else '65 years and over')\n",
    "\n",
    "censusIncome['wage_label'] = censusIncome['wage per hour'].apply(lambda value: '0-3000'\n",
    "if value <= 3000 else '3001-6000'\n",
    "if value <= 6000 else '6001-7000'\n",
    "if value <= 7000 else '7001-9000+')\n",
    "\n",
    "filteredCensus = censusIncome[\n",
    "    (censusIncome['class of worker'] != ' Not in universe') &\n",
    "    (censusIncome['education'] != ' Children') &\n",
    "    (censusIncome['wage per hour'] > 0) &\n",
    "    (censusIncome['weeks worked in year'] > 0)\n",
    "    ]\n",
    "\n",
    "filteredCensus = filteredCensus.drop(\"age\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"wage per hour\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"year\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"ignore\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"instance weight\", axis=1)\n",
    "\n",
    "filteredCensus.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encode the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "     class of worker_ Local government  class of worker_ Private  \\\n5                                    0                         1   \n8                                    1                         0   \n22                                   0                         1   \n49                                   0                         1   \n147                                  0                         0   \n\n     class of worker_ State government  detailed industry recode_2  \\\n5                                    0                           0   \n8                                    0                           0   \n22                                   0                           0   \n49                                   0                           0   \n147                                  1                           0   \n\n     detailed industry recode_3  detailed industry recode_4  \\\n5                             0                           0   \n8                             0                           0   \n22                            0                           0   \n49                            0                           0   \n147                           0                           0   \n\n     detailed industry recode_5  detailed industry recode_6  \\\n5                             0                           0   \n8                             0                           0   \n22                            0                           0   \n49                            0                           0   \n147                           0                           0   \n\n     detailed industry recode_7  detailed industry recode_8  ...  \\\n5                             0                           0  ...   \n8                             0                           0  ...   \n22                            0                           0  ...   \n49                            0                           0  ...   \n147                           0                           0  ...   \n\n     weeks worked in year_49  weeks worked in year_50  \\\n5                          0                        0   \n8                          0                        0   \n22                         0                        0   \n49                         0                        0   \n147                        0                        0   \n\n     weeks worked in year_51  weeks worked in year_52  age_label_25-54  \\\n5                          0                        1                1   \n8                          0                        1                1   \n22                         0                        0                0   \n49                         0                        1                0   \n147                        0                        0                0   \n\n     age_label_55-64  age_label_65 years and over  wage_label_3001-6000  \\\n5                  0                            0                     0   \n8                  0                            0                     0   \n22                 1                            0                     0   \n49                 0                            1                     0   \n147                0                            0                     0   \n\n     wage_label_6001-7000  wage_label_7001-9000+  \n5                       0                      0  \n8                       0                      0  \n22                      0                      0  \n49                      0                      0  \n147                     0                      0  \n\n[5 rows x 911 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class of worker_ Local government</th>\n      <th>class of worker_ Private</th>\n      <th>class of worker_ State government</th>\n      <th>detailed industry recode_2</th>\n      <th>detailed industry recode_3</th>\n      <th>detailed industry recode_4</th>\n      <th>detailed industry recode_5</th>\n      <th>detailed industry recode_6</th>\n      <th>detailed industry recode_7</th>\n      <th>detailed industry recode_8</th>\n      <th>...</th>\n      <th>weeks worked in year_49</th>\n      <th>weeks worked in year_50</th>\n      <th>weeks worked in year_51</th>\n      <th>weeks worked in year_52</th>\n      <th>age_label_25-54</th>\n      <th>age_label_55-64</th>\n      <th>age_label_65 years and over</th>\n      <th>wage_label_3001-6000</th>\n      <th>wage_label_6001-7000</th>\n      <th>wage_label_7001-9000+</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 911 columns</p>\n</div>"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode the dataset\n",
    "encodedIncome = pd.get_dummies(filteredCensus, columns=filteredCensus.columns, drop_first=True)\n",
    "encodedIncome.head()\n",
    "\n",
    "# print(encodedIncome.columns)\n",
    "\n",
    "# encodedIncome.to_csv('output.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " ...\n",
      " [-0.27467111 -2.44929625  5.04637987 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]]\n",
      "X_test: [[-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " ...\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]\n",
      " [-0.27467111  0.40828054 -0.19816186 ... -0.07917536 -0.02328101\n",
      "  -0.04034577]]\n",
      "y_train: 37558     1\n",
      "51629     1\n",
      "144257    1\n",
      "20616     1\n",
      "65333     1\n",
      "         ..\n",
      "190807    1\n",
      "23739     1\n",
      "163833    1\n",
      "109844    1\n",
      "197403    1\n",
      "Name: race_ White, Length: 7384, dtype: uint8\n",
      "y_test: 150252    1\n",
      "103270    1\n",
      "79793     1\n",
      "191666    0\n",
      "159554    1\n",
      "         ..\n",
      "109783    1\n",
      "52214     0\n",
      "120748    1\n",
      "161083    1\n",
      "165594    1\n",
      "Name: race_ White, Length: 3637, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# What do we predict?\n",
    "xAxis = encodedIncome.drop('race_ White', axis=1)\n",
    "yAxis = encodedIncome['race_ White']\n",
    "\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(\n",
    "    xAxis,\n",
    "    yAxis,\n",
    "    test_size=0.33,\n",
    "    random_state=21006\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainData)\n",
    "\n",
    "xTrain = scaler.transform(trainData)\n",
    "xTest = scaler.transform(testData)\n",
    "\n",
    "print(\"X_train:\", xTrain)\n",
    "print(\"X_test:\", xTest)\n",
    "print(\"y_train:\", trainLabels)\n",
    "print(\"y_test:\", testLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "def printTrainTimes(alogrithm, trainTimes, predictionTimes, accuracyTimes, f1Times, accuracyScores, f1Scores):\n",
    "    meanTrainTime = statistics.mean(trainTimes)\n",
    "    meanPredictionTime = statistics.mean(predictionTimes)\n",
    "    meanAccuracyTime = statistics.mean(accuracyTimes)\n",
    "    meanF1Time = statistics.mean(f1Times)\n",
    "    meanF1Score = statistics.mean(f1Scores)\n",
    "    meanAccuracyScore = statistics.mean(accuracyScores)\n",
    "\n",
    "    print('Algorithm:', alogrithm)\n",
    "\n",
    "    print('Mean times')\n",
    "\n",
    "    print('Mean training time:', meanTrainTime, 's')\n",
    "    print('Mean test time:', meanPredictionTime, 's')\n",
    "    print('Mean accuracy time:', meanAccuracyTime, 's')\n",
    "    print('Mean F1 time:', meanF1Time, 's')\n",
    "\n",
    "    print('Mean scores')\n",
    "\n",
    "    print('Mean accuracy score:', meanF1Score * 100, '%')\n",
    "    print('Mean F1 score:', meanAccuracyScore * 100, '%')\n",
    "    print()\n",
    "\n",
    "    return [\n",
    "        alogrithm,\n",
    "        str(\"{:.5f}s\".format(meanTrainTime)),\n",
    "        str(\"{:.5f}s\".format(meanPredictionTime)),\n",
    "        str(\"{:.5f}s\".format(meanAccuracyTime)),\n",
    "        str(\"{:.5f}s\".format(meanF1Time)),\n",
    "        str(\"{:.2f}%\".format(meanAccuracyScore * 100)),\n",
    "        str(\"{:.2f}%\".format(meanF1Score * 100))\n",
    "    ]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN (k-Nearest-Neighbor Classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest-Neighbor with 2 neighbors\n",
      "Training time: 1.6319575309753418 s\n",
      "Testing time: 34.24049091339111 s\n",
      "Accuracy time: 0.0005550384521484375 s\n",
      "F1 time: 0.0017056465148925781 s\n",
      "\n",
      "Accuracy: 80.53340665383558 %\n",
      "F1 score: 81.73393161683573 %\n",
      "\n",
      "k-Nearest-Neighbor with 4 neighbors\n",
      "Training time: 1.6315422058105469 s\n",
      "Testing time: 38.50601148605347 s\n",
      "Accuracy time: 0.0005671977996826172 s\n",
      "F1 time: 0.0013189315795898438 s\n",
      "\n",
      "Accuracy: 86.60984327742645 %\n",
      "F1 score: 85.24623652355848 %\n",
      "\n",
      "k-Nearest-Neighbor with 6 neighbors\n",
      "Training time: 1.5365197658538818 s\n",
      "Testing time: 41.92724323272705 s\n",
      "Accuracy time: 0.000507354736328125 s\n",
      "F1 time: 0.0014867782592773438 s\n",
      "\n",
      "Accuracy: 87.8746219411603 %\n",
      "F1 score: 85.60203264144111 %\n",
      "\n",
      "Algorithm: k-Nearest-Neighbor\n",
      "Mean times\n",
      "Mean training time: 1.6000065008799236 s\n",
      "Mean test time: 38.22458187739054 s\n",
      "Mean accuracy time: 0.0005431969960530599 s\n",
      "Mean F1 time: 0.0015037854512532551 s\n",
      "Mean scores\n",
      "Mean accuracy score: 84.19406692727844 %\n",
      "Mean F1 score: 85.00595729080744 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://python-course.eu/machine-learning/k-nearest-neighbor-classifier-with-sklearn.php\n",
    "\n",
    "kValues = [2, 4, 6]\n",
    "\n",
    "f1Scores = []\n",
    "accuracyScores = []\n",
    "\n",
    "trainTimes = []\n",
    "predictionTimes = []\n",
    "accuracyTimes = []\n",
    "f1Times = []\n",
    "\n",
    "for k in kValues:\n",
    "    print('k-Nearest-Neighbor with', k, 'neighbors')\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n",
    "\n",
    "    # Train the algorithm\n",
    "    start = time.time()\n",
    "    knn.fit(xTrain, trainLabels)\n",
    "    end = time.time()\n",
    "    trainTime = end - start\n",
    "    trainTimes.append(end - start)\n",
    "\n",
    "    # Predict\n",
    "    start = time.time()\n",
    "    predicted = knn.predict(xTest)\n",
    "    end = time.time()\n",
    "    predictionTime = end - start\n",
    "    predictionTimes.append(end - start)\n",
    "\n",
    "    # Effectiveness measurement\n",
    "\n",
    "    # To evaluate the result, we will use the accuracy score\n",
    "    start = time.time()\n",
    "    accuracyScore = accuracy_score(testLabels, predicted)\n",
    "    end = time.time()\n",
    "    accuracyScores.append(accuracyScore)\n",
    "    accuracyTime = (end - start)\n",
    "    accuracyTimes.append(accuracyTime)\n",
    "\n",
    "    # To evaluate the result, we will use the f1_score\n",
    "    start = time.time()\n",
    "    f1Score = f1_score(testLabels, predicted, average='weighted')\n",
    "    end = time.time()\n",
    "    f1Scores.append(f1Score)\n",
    "    f1Time = end - start\n",
    "    f1Times.append(f1Time)\n",
    "\n",
    "    print('Training time:', trainTime, 's')\n",
    "    print('Testing time:', predictionTime, 's')\n",
    "    print('Accuracy time:', accuracyTime, 's')\n",
    "    print('F1 time:', f1Time, 's')\n",
    "    print()\n",
    "\n",
    "    print('Accuracy:', accuracyScore * 100, '%')\n",
    "    print('F1 score:', f1Score * 100, '%')\n",
    "    print()\n",
    "\n",
    "knnResults = printTrainTimes('k-Nearest-Neighbor', trainTimes, predictionTimes, accuracyTimes, f1Times,\n",
    "                             accuracyScores, f1Scores)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN produces very good results. The best accuracy was achieved with 6 neighbors. The execution is the longest of the three algorithms. Therefore, I switched to kd-tree algorithm, otherwise the runtime was not acceptable. WIth kd-tree the runtime is acceptable, but still the slowest.\n",
    "\n",
    "Overall the accuracy and the f1-score are very good along all neighbors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perceptron"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron with alpha 0.1 and penalty l2\n",
      "Training time: 0.1498417854309082 s\n",
      "Testing time: 0.0036530494689941406 s\n",
      "Accuracy time: 0.0005824565887451172 s\n",
      "F1 time: 0.0017695426940917969 s\n",
      "\n",
      "Accuracy: 82.59554577948859 %\n",
      "F1 score: 79.24263226963689 %\n",
      "\n",
      "Perceptron with alpha 0.1 and penalty l1\n",
      "Training time: 0.22814011573791504 s\n",
      "Testing time: 0.004194974899291992 s\n",
      "Accuracy time: 0.0005702972412109375 s\n",
      "F1 time: 0.0034019947052001953 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 0.31622776601683794 and penalty l2\n",
      "Training time: 0.15801501274108887 s\n",
      "Testing time: 0.0037915706634521484 s\n",
      "Accuracy time: 0.0005228519439697266 s\n",
      "F1 time: 0.0015716552734375 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 0.31622776601683794 and penalty l1\n",
      "Training time: 0.2955293655395508 s\n",
      "Testing time: 0.004208087921142578 s\n",
      "Accuracy time: 0.00046825408935546875 s\n",
      "F1 time: 0.0012392997741699219 s\n",
      "\n",
      "Accuracy: 14.902392081385758 %\n",
      "F1 score: 3.8655642537023596 %\n",
      "\n",
      "Perceptron with alpha 1.0 and penalty l2\n",
      "Training time: 0.17600440979003906 s\n",
      "Testing time: 0.004246950149536133 s\n",
      "Accuracy time: 0.0006849765777587891 s\n",
      "F1 time: 0.0017654895782470703 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 1.0 and penalty l1\n",
      "Training time: 0.3133869171142578 s\n",
      "Testing time: 0.009554862976074219 s\n",
      "Accuracy time: 0.0006527900695800781 s\n",
      "F1 time: 0.0014426708221435547 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 3.1622776601683795 and penalty l2\n",
      "Training time: 0.1636354923248291 s\n",
      "Testing time: 0.014258146286010742 s\n",
      "Accuracy time: 0.0005745887756347656 s\n",
      "F1 time: 0.0015938282012939453 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 3.1622776601683795 and penalty l1\n",
      "Training time: 0.3174598217010498 s\n",
      "Testing time: 0.02317643165588379 s\n",
      "Accuracy time: 0.0005357265472412109 s\n",
      "F1 time: 0.001583099365234375 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 10.0 and penalty l2\n",
      "Training time: 0.17139601707458496 s\n",
      "Testing time: 0.023329734802246094 s\n",
      "Accuracy time: 0.0013997554779052734 s\n",
      "F1 time: 0.002239227294921875 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Perceptron with alpha 10.0 and penalty l1\n",
      "Training time: 0.33863043785095215 s\n",
      "Testing time: 0.033806800842285156 s\n",
      "Accuracy time: 0.0005767345428466797 s\n",
      "F1 time: 0.0018274784088134766 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Algorithm: Perceptron\n",
      "Mean times\n",
      "Mean training time: 0.23120393753051757 s\n",
      "Mean test time: 0.0124220609664917 s\n",
      "Mean accuracy time: 0.0006568431854248047 s\n",
      "Mean F1 time: 0.001843428611755371 s\n",
      "Mean scores\n",
      "Mean accuracy score: 70.90787170417256 %\n",
      "Mean F1 score: 77.82788012097882 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1Scores = []\n",
    "accuracyScores = []\n",
    "\n",
    "trainTimes = []\n",
    "predictionTimes = []\n",
    "accuracyTimes = []\n",
    "f1Times = []\n",
    "\n",
    "alphas = np.logspace(-1, 1, 5)\n",
    "penalties = ['l2', 'l1']\n",
    "\n",
    "for a in alphas:\n",
    "    for p in penalties:\n",
    "        print('Perceptron with alpha', a, 'and penalty', p)\n",
    "\n",
    "        perceptron = Perceptron(alpha=a, penalty=p)\n",
    "\n",
    "        # Train the algorithm\n",
    "        start = time.time()\n",
    "        perceptron.fit(xTrain, trainLabels)\n",
    "        end = time.time()\n",
    "        trainTime = end - start\n",
    "        trainTimes.append(end - start)\n",
    "\n",
    "        # Predict\n",
    "        start = time.time()\n",
    "        predicted = perceptron.predict(xTest)\n",
    "        end = time.time()\n",
    "        predictionTime = end - start\n",
    "        predictionTimes.append(end - start)\n",
    "\n",
    "        # Effectiveness measurement\n",
    "        start = time.time()\n",
    "        accuracyScore = accuracy_score(testLabels, predicted)\n",
    "        end = time.time()\n",
    "        accuracyScores.append(accuracyScore)\n",
    "        accuracyTime = (end - start)\n",
    "        accuracyTimes.append(accuracyTime)\n",
    "\n",
    "        # To evaluate the result, we will use the f1_score\n",
    "        start = time.time()\n",
    "        f1Score = f1_score(testLabels, predicted, average='weighted')\n",
    "        end = time.time()\n",
    "        f1Scores.append(f1Score)\n",
    "        f1Time = end - start\n",
    "        f1Times.append(f1Time)\n",
    "\n",
    "        print('Training time:', trainTime, 's')\n",
    "        print('Testing time:', predictionTime, 's')\n",
    "        print('Accuracy time:', accuracyTime, 's')\n",
    "        print('F1 time:', f1Time, 's')\n",
    "        print()\n",
    "\n",
    "        print('Accuracy:', accuracyScore * 100, '%')\n",
    "        print('F1 score:', f1Score * 100, '%')\n",
    "        print()\n",
    "\n",
    "perceptronResults = printTrainTimes('Perceptron', trainTimes, predictionTimes, accuracyTimes, f1Times, accuracyScores,\n",
    "                                    f1Scores)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The runtime of this algorithm is much faster than the runtime of the knn algorithm. It performs the best out of the three algorithms. THe accuracy and the f1-score are very good and constant over all parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with min sample splits 2 and min sample leafs 1\n",
      "Training time: 0.5715327262878418 s\n",
      "Testing time: 0.005532979965209961 s\n",
      "Accuracy time: 0.0005567073822021484 s\n",
      "F1 time: 0.0015556812286376953 s\n",
      "\n",
      "Accuracy: 97.82788012097883 %\n",
      "F1 score: 97.82036431907973 %\n",
      "\n",
      "Decision Tree with min sample splits 2 and min sample leafs 25\n",
      "Training time: 0.3790569305419922 s\n",
      "Testing time: 0.006223440170288086 s\n",
      "Accuracy time: 0.0005769729614257812 s\n",
      "F1 time: 0.0013267993927001953 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 2 and min sample leafs 50\n",
      "Training time: 0.3062736988067627 s\n",
      "Testing time: 0.004942178726196289 s\n",
      "Accuracy time: 0.0006055831909179688 s\n",
      "F1 time: 0.002058744430541992 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 2 and min sample leafs 100\n",
      "Training time: 0.2425541877746582 s\n",
      "Testing time: 0.004795551300048828 s\n",
      "Accuracy time: 0.0006315708160400391 s\n",
      "F1 time: 0.0016608238220214844 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 2 and min sample leafs 1000\n",
      "Training time: 0.07441377639770508 s\n",
      "Testing time: 0.004517316818237305 s\n",
      "Accuracy time: 0.00047969818115234375 s\n",
      "F1 time: 0.0015239715576171875 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Decision Tree with min sample splits 25 and min sample leafs 1\n",
      "Training time: 0.56166672706604 s\n",
      "Testing time: 0.005532503128051758 s\n",
      "Accuracy time: 0.0006475448608398438 s\n",
      "F1 time: 0.0016307830810546875 s\n",
      "\n",
      "Accuracy: 98.24030794610943 %\n",
      "F1 score: 98.22378508626328 %\n",
      "\n",
      "Decision Tree with min sample splits 25 and min sample leafs 25\n",
      "Training time: 0.407625675201416 s\n",
      "Testing time: 0.005504608154296875 s\n",
      "Accuracy time: 0.0005517005920410156 s\n",
      "F1 time: 0.0017392635345458984 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 25 and min sample leafs 50\n",
      "Training time: 0.3097548484802246 s\n",
      "Testing time: 0.005167722702026367 s\n",
      "Accuracy time: 0.0006036758422851562 s\n",
      "F1 time: 0.0015265941619873047 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 25 and min sample leafs 100\n",
      "Training time: 0.24615097045898438 s\n",
      "Testing time: 0.005686283111572266 s\n",
      "Accuracy time: 0.0006911754608154297 s\n",
      "F1 time: 0.0020623207092285156 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 25 and min sample leafs 1000\n",
      "Training time: 0.0819704532623291 s\n",
      "Testing time: 0.0061473846435546875 s\n",
      "Accuracy time: 0.0006325244903564453 s\n",
      "F1 time: 0.0023818016052246094 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Decision Tree with min sample splits 50 and min sample leafs 1\n",
      "Training time: 0.6099510192871094 s\n",
      "Testing time: 0.005502462387084961 s\n",
      "Accuracy time: 0.0005748271942138672 s\n",
      "F1 time: 0.0016374588012695312 s\n",
      "\n",
      "Accuracy: 98.40527907616166 %\n",
      "F1 score: 98.38642959685633 %\n",
      "\n",
      "Decision Tree with min sample splits 50 and min sample leafs 25\n",
      "Training time: 0.38574886322021484 s\n",
      "Testing time: 0.004778861999511719 s\n",
      "Accuracy time: 0.0005145072937011719 s\n",
      "F1 time: 0.0016887187957763672 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 50 and min sample leafs 50\n",
      "Training time: 0.2945823669433594 s\n",
      "Testing time: 0.006223440170288086 s\n",
      "Accuracy time: 0.0005462169647216797 s\n",
      "F1 time: 0.001722097396850586 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 50 and min sample leafs 100\n",
      "Training time: 0.22382736206054688 s\n",
      "Testing time: 0.005089998245239258 s\n",
      "Accuracy time: 0.0005402565002441406 s\n",
      "F1 time: 0.0015344619750976562 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 50 and min sample leafs 1000\n",
      "Training time: 0.07144761085510254 s\n",
      "Testing time: 0.0049817562103271484 s\n",
      "Accuracy time: 0.0004987716674804688 s\n",
      "F1 time: 0.0017147064208984375 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Decision Tree with min sample splits 100 and min sample leafs 1\n",
      "Training time: 0.589362382888794 s\n",
      "Testing time: 0.005486726760864258 s\n",
      "Accuracy time: 0.0005388259887695312 s\n",
      "F1 time: 0.0016355514526367188 s\n",
      "\n",
      "Accuracy: 98.40527907616166 %\n",
      "F1 score: 98.38642959685633 %\n",
      "\n",
      "Decision Tree with min sample splits 100 and min sample leafs 25\n",
      "Training time: 0.39663219451904297 s\n",
      "Testing time: 0.005268096923828125 s\n",
      "Accuracy time: 0.0006995201110839844 s\n",
      "F1 time: 0.001874685287475586 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 100 and min sample leafs 50\n",
      "Training time: 0.30652618408203125 s\n",
      "Testing time: 0.006103038787841797 s\n",
      "Accuracy time: 0.0006594657897949219 s\n",
      "F1 time: 0.001817941665649414 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 100 and min sample leafs 100\n",
      "Training time: 0.2304859161376953 s\n",
      "Testing time: 0.005224466323852539 s\n",
      "Accuracy time: 0.0005598068237304688 s\n",
      "F1 time: 0.0015103816986083984 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 100 and min sample leafs 1000\n",
      "Training time: 0.0702364444732666 s\n",
      "Testing time: 0.004909992218017578 s\n",
      "Accuracy time: 0.0005071163177490234 s\n",
      "F1 time: 0.0015609264373779297 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Decision Tree with min sample splits 250 and min sample leafs 1\n",
      "Training time: 0.5660760402679443 s\n",
      "Testing time: 0.006262302398681641 s\n",
      "Accuracy time: 0.0007197856903076172 s\n",
      "F1 time: 0.0018665790557861328 s\n",
      "\n",
      "Accuracy: 98.51525982952984 %\n",
      "F1 score: 98.49527654272694 %\n",
      "\n",
      "Decision Tree with min sample splits 250 and min sample leafs 25\n",
      "Training time: 0.37529468536376953 s\n",
      "Testing time: 0.0060498714447021484 s\n",
      "Accuracy time: 0.0006461143493652344 s\n",
      "F1 time: 0.0017218589782714844 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 250 and min sample leafs 50\n",
      "Training time: 0.3069286346435547 s\n",
      "Testing time: 0.005067348480224609 s\n",
      "Accuracy time: 0.0005519390106201172 s\n",
      "F1 time: 0.0015532970428466797 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 250 and min sample leafs 100\n",
      "Training time: 0.23446917533874512 s\n",
      "Testing time: 0.006719350814819336 s\n",
      "Accuracy time: 0.0008769035339355469 s\n",
      "F1 time: 0.0023670196533203125 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 250 and min sample leafs 1000\n",
      "Training time: 0.0803823471069336 s\n",
      "Testing time: 0.00530695915222168 s\n",
      "Accuracy time: 0.0005242824554443359 s\n",
      "F1 time: 0.0015146732330322266 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Decision Tree with min sample splits 1000 and min sample leafs 1\n",
      "Training time: 0.5492594242095947 s\n",
      "Testing time: 0.0054056644439697266 s\n",
      "Accuracy time: 0.0005421638488769531 s\n",
      "F1 time: 0.001516580581665039 s\n",
      "\n",
      "Accuracy: 98.73522133626615 %\n",
      "F1 score: 98.71292985031636 %\n",
      "\n",
      "Decision Tree with min sample splits 1000 and min sample leafs 25\n",
      "Training time: 0.35352540016174316 s\n",
      "Testing time: 0.005189418792724609 s\n",
      "Accuracy time: 0.0008959770202636719 s\n",
      "F1 time: 0.0016427040100097656 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 1000 and min sample leafs 50\n",
      "Training time: 0.2637350559234619 s\n",
      "Testing time: 0.005051374435424805 s\n",
      "Accuracy time: 0.0006268024444580078 s\n",
      "F1 time: 0.002181529998779297 s\n",
      "\n",
      "Accuracy: 98.7627165246082 %\n",
      "F1 score: 98.74038754547475 %\n",
      "\n",
      "Decision Tree with min sample splits 1000 and min sample leafs 100\n",
      "Training time: 0.19553685188293457 s\n",
      "Testing time: 0.0060882568359375 s\n",
      "Accuracy time: 0.0006659030914306641 s\n",
      "F1 time: 0.0020761489868164062 s\n",
      "\n",
      "Accuracy: 97.80038493263679 %\n",
      "F1 score: 97.72678349821668 %\n",
      "\n",
      "Decision Tree with min sample splits 1000 and min sample leafs 1000\n",
      "Training time: 0.07181763648986816 s\n",
      "Testing time: 0.0048065185546875 s\n",
      "Accuracy time: 0.0006113052368164062 s\n",
      "F1 time: 0.001676797866821289 s\n",
      "\n",
      "Accuracy: 85.09760791861424 %\n",
      "F1 score: 78.2463150647983 %\n",
      "\n",
      "Algorithm: DecisionTree\n",
      "Mean times\n",
      "Mean training time: 0.3118941863377889 s\n",
      "Mean test time: 0.005452195803324382 s\n",
      "Mean accuracy time: 0.0006092548370361328 s\n",
      "Mean F1 time: 0.0017426967620849609 s\n",
      "Mean scores\n",
      "Mean accuracy score: 94.35828189719619 %\n",
      "Mean F1 score: 95.75565942626707 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1Scores = []\n",
    "accuracyScores = []\n",
    "\n",
    "trainTimes = []\n",
    "predictionTimes = []\n",
    "accuracyTimes = []\n",
    "f1Times = []\n",
    "\n",
    "# algo input parameter variation lists\n",
    "minSamplesSplits = [2, 25, 50, 100, 250, 1000]\n",
    "minSamplesLeafs = [1, 25, 50, 100, 1000]\n",
    "\n",
    "for mSS in minSamplesSplits:\n",
    "    for mSL in minSamplesLeafs:\n",
    "        print('Decision Tree with min sample splits', mSS, 'and min sample leafs', mSL)\n",
    "\n",
    "        decisionTree = DecisionTreeClassifier(\n",
    "            min_samples_split=mSS,\n",
    "            min_samples_leaf=mSL\n",
    "        )\n",
    "\n",
    "        # Train the algorithm\n",
    "        start = time.time()\n",
    "        decisionTree.fit(xTrain, trainLabels)\n",
    "        end = time.time()\n",
    "        trainTime = end - start\n",
    "        trainTimes.append(end - start)\n",
    "\n",
    "        # Predict\n",
    "        start = time.time()\n",
    "        predicted = decisionTree.predict(xTest)\n",
    "        end = time.time()\n",
    "        predictionTime = end - start\n",
    "        predictionTimes.append(end - start)\n",
    "\n",
    "        # Effectiveness measurement\n",
    "        start = time.time()\n",
    "        accuracyScore = accuracy_score(testLabels, predicted)\n",
    "        end = time.time()\n",
    "        accuracyScores.append(accuracyScore)\n",
    "        accuracyTime = (end - start)\n",
    "        accuracyTimes.append(accuracyTime)\n",
    "\n",
    "        # To evaluate the result, we will use the f1_score\n",
    "        start = time.time()\n",
    "        f1Score = f1_score(testLabels, predicted, average='weighted')\n",
    "        end = time.time()\n",
    "        f1Scores.append(f1Score)\n",
    "        f1Time = end - start\n",
    "        f1Times.append(f1Time)\n",
    "\n",
    "        print('Training time:', trainTime, 's')\n",
    "        print('Testing time:', predictionTime, 's')\n",
    "        print('Accuracy time:', accuracyTime, 's')\n",
    "        print('F1 time:', f1Time, 's')\n",
    "        print()\n",
    "\n",
    "        print('Accuracy:', accuracyScore * 100, '%')\n",
    "        print('F1 score:', f1Score * 100, '%')\n",
    "        print()\n",
    "\n",
    "decisionTreeResults = printTrainTimes('DecisionTree', trainTimes, predictionTimes, accuracyTimes, f1Times,\n",
    "                                      accuracyScores, f1Scores)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The decision tree has the second-best runtime of the algorithms. The accuracy and the f1-score is constantly very high and has the best results of all three algorithms."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "Here I compared the mean times and mean scores of all three algorithms."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------------------+----------------------+----------------+------------+--------+\n",
      "| Algorithm          | Mean Train Time   | Mean Prediction Time   | Mean Accuracy Time   | Mean F1 Time   | Accuracy   | F1     |\n",
      "+====================+===================+========================+======================+================+============+========+\n",
      "| k-Nearest-Neighbor | 1.60001s          | 38.22458s              | 0.00054s             | 0.00150s       | 85.01%     | 84.19% |\n",
      "+--------------------+-------------------+------------------------+----------------------+----------------+------------+--------+\n",
      "| Perceptron         | 0.23120s          | 0.01242s               | 0.00066s             | 0.00184s       | 77.83%     | 70.91% |\n",
      "+--------------------+-------------------+------------------------+----------------------+----------------+------------+--------+\n",
      "| DecisionTree       | 0.31189s          | 0.00545s               | 0.00061s             | 0.00174s       | 95.76%     | 94.36% |\n",
      "+--------------------+-------------------+------------------------+----------------------+----------------+------------+--------+\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            knnResults,\n",
    "            perceptronResults,\n",
    "            decisionTreeResults\n",
    "        ],\n",
    "        [\"Algorithm\", \"Mean Train Time\", \"Mean Prediction Time\", \"Mean Accuracy Time\", \"Mean F1 Time\", \"Accuracy\",\n",
    "         \"F1\"],\n",
    "        tablefmt=\"grid\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above we see that knn is the slowest of the three algorithms. knn performs the second-best accuracy and f1-score. The perceptron is the fastest of the three algorithms, but produces the least accurate accuracy- and f1-scores. Decision tree produces the best results. It has a very good accuracy and f1-score.\n",
    "\n",
    "By removing some columns from the dataset the computation time was reduced drastically and the and the accuracy and f1-score increased."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}